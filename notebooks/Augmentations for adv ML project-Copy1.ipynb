{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_aug_dataset_3' from 'augmentation_tools' (/home/therien/Documents/github/adaptive_auto_attack/notebooks/../augmentation_tools.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maugmentation_tools\u001b[39;00m\n\u001b[1;32m     37\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(augmentation_tools)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maugmentation_tools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (showPoly, get_warped_corners_image, get_valid_affine_range,\n\u001b[1;32m     39\u001b[0m SSTransformation, square_in_sqare, get_aug_dataset_3, show_reg_aug_side_by_side_3,save_im_and_label)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_aug_dataset_3' from 'augmentation_tools' (/home/therien/Documents/github/adaptive_auto_attack/notebooks/../augmentation_tools.py)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# It is best to start with USE_GPU = False (implying CPU). Switch USE_GPU to True only if you want to use GPU. However... \n",
    "# we strongly recommend to wait until you are absolutely sure your CPU-based code works (at least on single image dataset)\n",
    "USE_GPU = True\n",
    "\n",
    "# Python Libraries\n",
    "import random\n",
    "import math\n",
    "import numbers\n",
    "import platform\n",
    "import copy\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Importing essential libraries for basic image manipulations.\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as tF\n",
    "\n",
    "\n",
    "from matplotlib.patches import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import augmentation_tools\n",
    "importlib.reload(augmentation_tools)\n",
    "from augmentation_tools import (showPoly, get_warped_corners_image, get_valid_affine_range,\n",
    "SSTransformation, square_in_sqare, get_aug_dataset_3, show_reg_aug_side_by_side_3,save_im_and_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision' has no attribute 'InterpolationMode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMNIST\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcifar10\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m dataset_regular, dataset_aug, dataset_RT \u001b[38;5;241m=\u001b[39m \u001b[43mget_aug_dataset_3\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_root_ovr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43msstransformation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_r\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m45.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2248\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/adaptive_auto_attack/notebooks/../augmentation_tools.py:575\u001b[0m, in \u001b[0;36mget_aug_dataset_3\u001b[0;34m(dataset, use_train, data_root_ovr, sstransformation, seed)\u001b[0m\n\u001b[1;32m    571\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor()])\n\u001b[1;32m    572\u001b[0m transform_aug \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([SSTransformation(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msstransformation),\n\u001b[1;32m    573\u001b[0m                                         transforms\u001b[38;5;241m.\u001b[39mToTensor()])\n\u001b[1;32m    574\u001b[0m transform_RT \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mRandomAffine(degrees\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m30\u001b[39m), translate\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), \n\u001b[0;32m--> 575\u001b[0m                                     scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInterpolationMode\u001b[49m\u001b[38;5;241m.\u001b[39mBILINEAR),\n\u001b[1;32m    576\u001b[0m                                         transforms\u001b[38;5;241m.\u001b[39mToTensor()])\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcifar10\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    579\u001b[0m     dataset_regular \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39mDATAROOT, train\u001b[38;5;241m=\u001b[39muse_train,\n\u001b[1;32m    580\u001b[0m                                                    download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision' has no attribute 'InterpolationMode'"
     ]
    }
   ],
   "source": [
    "# dataset = 'cub2011'\n",
    "dataset = 'MNIST'\n",
    "dataset = 'cifar10'\n",
    "\n",
    "\n",
    "dataset_regular, dataset_aug, dataset_RT = get_aug_dataset_3(\n",
    "        dataset=dataset, \n",
    "        use_train=False, \n",
    "        data_root_ovr=None, \n",
    "        sstransformation=dict(max_r=45.,\n",
    "    max_t=30.,\n",
    "    max_s=1.2248,),\n",
    "        seed=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "if SAVE == True:\n",
    "    save_im_and_label(filepath='../numpy_datasets/{}_augmented'.format(dataset),dataset=dataset_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following cell vizualizes the dataset with and without augmentations. Even rows are augmented, while odd rows are clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if dataset == 'MNIST':\n",
    "    cmap = 'gray'\n",
    "else:\n",
    "    cmap = None\n",
    "    \n",
    "show_reg_aug_side_by_side(\n",
    "    dataset_regular,\n",
    "    dataset_aug,\n",
    "    total_plots=40,\n",
    "    plots_per_row=5,\n",
    "    figsize=(20,67),\n",
    "    savepath=None,\n",
    "    cmap=cmap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showPoly(outCorners=np.array([[-4.5691323,  3.3351207],[3.3351207,  4.5691323],\n",
    "                                                       [4.5691323, -3.3351207],[-3.3351207, -4.5691323]]), \n",
    "                           inCorners=np.array([[ 2., -2.],[ 2.,  2.],[-2.,  2.],[-2., -2.]]))\n",
    "    \n",
    "#     outCorners=np.array([[23.765, 66.235],[66.235, 66.235],[66.235, 23.765],[23.765, 23.765]]), \n",
    "#          inCorners=np.array([[-15.5,  15.5],[ 15.5,  15.5],[ 15.5, -15.5],[-15.5, -15.5]]))\n",
    " \n",
    "is_in = square_in_sqare(\n",
    "    outCorners=np.array([[23.765, 66.235],[66.235, 66.235],[66.235, 23.765],[23.765, 23.765]]), \n",
    "    inCorners=np.array([[-15.5,  15.5],[ 15.5,  15.5],[ 15.5, -15.5],[-15.5, -15.5]])\n",
    ")\n",
    "\n",
    "assert is_in == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import SimilarityTransform\n",
    "im = np.random.randn(32,32,3)\n",
    "scale = 1.2248\n",
    "scaled = get_warped_corners_image(im, SimilarityTransform(scale=scale))\n",
    "\n",
    "valid_r = get_valid_affine_range(\n",
    "    warped_corners=scaled['warpedcorners'],orig_corners=scaled['corners'],\n",
    "    max_=45, affine_type='rotation',threshold=0.001\n",
    ")\n",
    "print(valid_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
